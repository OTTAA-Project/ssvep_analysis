{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32dfdc86",
   "metadata": {},
   "source": [
    "## Signal Analysis\n",
    "This script is aimed to analyze the signals proposed for BCI usage for the MACI proposal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300d6e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.signal as sgn\n",
    "import scipy.interpolate as sip\n",
    "\n",
    "from Signal import Signal\n",
    "from Dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a4618c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './stim_23'\n",
    "PATH_RAW = os.path.join(PATH, 'train_data')\n",
    "PATH_FVS = os.path.join(PATH, 'fv_data')\n",
    "if not os.path.exists(PATH_FVS):\n",
    "    os.mkdir(PATH_FVS)\n",
    "PATH_RESULT = os.path.join(PATH, 'results')\n",
    "if not os.path.exists(PATH_RESULT):\n",
    "    os.mkdir(PATH_RESULT)\n",
    "\n",
    "SF = 200\n",
    "\n",
    "ORDER = 4\n",
    "BP_LO = 4\n",
    "BP_HI = 50\n",
    "NOTCH = 50\n",
    "\n",
    "WINDOW = 512\n",
    "STRIDE = 1\n",
    "\n",
    "FREQ = None #freq none takes it from the file name\n",
    "BW = 1\n",
    "HARMS = [1, 2]\n",
    "APPLY_SNR = True\n",
    "\n",
    "LAB_RELS = {\n",
    "    99: 0,\n",
    "    1: 1,\n",
    "    2: 2\n",
    "}\n",
    "\n",
    "SOURCE = 'freq'\n",
    "\n",
    "CHANNELS = None\n",
    "SUBJECTS = None\n",
    "SESSIONS = None\n",
    "LABELS = None\n",
    "\n",
    "freq_bin_values = list(np.arange(22, 24.1, 0.5)) + list(np.arange(45, 47.1, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbc05b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairplot_df(X, y, constant, df, clean = False):\n",
    "    stim_moment = 0 #position in the stimulation\n",
    "    stim_number = 0 #number of stimulation\n",
    "    \n",
    "    columns = df.columns\n",
    "    responses = []\n",
    "    for i, (feat, lab) in enumerate(zip(X, y)):\n",
    "        if lab[1] == 1.0:\n",
    "            max_peak_bin = feat.argmax()\n",
    "            max_peak_value = np.round(float(feat[max_peak_bin]), 1)\n",
    "            max_peak_channel = int(max_peak_bin // 10) #which channel has highest peak\n",
    "            max_peak_freq = int(max_peak_bin % 10) #which frequency has the highest peak independent of channel\n",
    "            if clean and any(\n",
    "                df[columns[0]] == constant &\n",
    "                df[columns[1]] == stim_number &\n",
    "                df[columns[2]] == stim_moment &\n",
    "                df[columns[3]] == max_peak_bin &\n",
    "                abs(df[columns[4]] - max_peak_value) <= 0.1 &\n",
    "                df[columns[5]] == max_peak_channel &\n",
    "                df[columns[6]] == max_peak_freq\n",
    "            ):\n",
    "                pass\n",
    "            else:\n",
    "                df = pd.concat((df, pd.DataFrame([[constant, stim_number, stim_moment, max_peak_bin, max_peak_value, max_peak_channel + 1, freq_bin_values[max_peak_freq]]], columns=df.columns)))\n",
    "            stim_moment += 1\n",
    "        elif stim_moment != 0:\n",
    "            ch, ch_counts = np.unique(df[columns[5]][-stim_moment:], return_counts=True)\n",
    "            prevalent_channel = ch[ch_counts.argmax()]\n",
    "            fr, fr_counts = np.unique(df[columns[5]][-stim_moment:], return_counts=True)\n",
    "            prevalent_freq = fr[fr_counts.argmax()]\n",
    "            response_raw = X[i-stim_moment:i, prevalent_channel+prevalent_freq]\n",
    "            response_raw_range = np.arange(response_raw.shape[0])\n",
    "            response_soft = np.interp(response_raw_range, response_raw_range[::10], response_raw[::10])\n",
    "            responses.append(response_soft)\n",
    "            stim_moment = 0\n",
    "            stim_number += 1\n",
    "    return df, responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2021745a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_peaks(s):\n",
    "    return {\n",
    "        'max': [100*s.argmax()/s.shape[0]], \n",
    "        'peaks': (100*sgn.find_peaks(s)[0]/s.shape[0]).tolist()\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18b3fb1",
   "metadata": {},
   "source": [
    "## Individual Analysis\n",
    "Analysis carried out user by user. While we analyze each one, we also generate the necessary files for the global analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8771b6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "each_user_current = None\n",
    "each_user_list = []\n",
    "user_list = []\n",
    "for f in os.listdir(PATH_RAW):\n",
    "    user = f.split(' ')[0]\n",
    "    if user != each_user_current:\n",
    "        each_user_current = user\n",
    "        if len(each_user_list) > 0:\n",
    "            user_list.append(each_user_list)\n",
    "        each_user_list = [os.path.join(PATH_RAW, f)]\n",
    "    else:\n",
    "        each_user_list.append(os.path.join(PATH_RAW, f))\n",
    "user_list.append(each_user_list)\n",
    "\n",
    "global_users = {}\n",
    "for i, user in enumerate(user_list):\n",
    "    db = Dataset(user, sf = SF, order = ORDER, bp_lo = BP_LO, bp_hi = BP_HI, notch = NOTCH,\n",
    "                window = WINDOW, stride = STRIDE, freq = FREQ, bw = BW, \n",
    "                harms = HARMS, apply_snr = APPLY_SNR, lab_rels = LAB_RELS\n",
    "                )\n",
    "    #here individual analysis\n",
    "    dataframe = pd.DataFrame(columns=[\"session\", \"stim_number\", \"stim_moment\", \"max_peak_bin\", \"max_peak_energy\", \"max_peak_channel\", \"max_peak_freq\"])\n",
    "    for sess in range(10):\n",
    "        try:\n",
    "            X = db.get_fv(source = SOURCE, channels = CHANNELS, subjects = SUBJECTS, \n",
    "                       sessions = [sess], labels = LABELS\n",
    "                      )\n",
    "            y = db.get_onehot(subjects = SUBJECTS, \n",
    "                       sessions = [sess], labels = LABELS\n",
    "                           )\n",
    "            dataframe, responses = pairplot_df(X, y, sess, dataframe)\n",
    "            #fig = plt.figure(figsize=(15,5)).suptitle(f'Prevalent channel for S{i} session {sess}')\n",
    "            #sns.lineplot(responses)\n",
    "            \n",
    "        except ValueError:\n",
    "            continue\n",
    "    \n",
    "    dataframe.pop('max_peak_bin') #for display this should not be necessary having channel and frequency\n",
    "    fig, axs = plt.subplots(1, len(dataframe.columns)-2)\n",
    "    fig.set_figheight(5)\n",
    "    fig.set_figwidth(30)\n",
    "    suptitle = fig.suptitle(f'Histograms for S{i}')\n",
    "    for n, ax in enumerate(axs[:-1]):\n",
    "        if dataframe.columns[n+3] != 'max_peak_energy':\n",
    "            sns.histplot(dataframe, x=dataframe.columns[n+3], hue=dataframe.columns[0], ax=ax, binwidth=0.5, binrange=(min(dataframe[dataframe.columns[n+3]]), 1+max(dataframe[dataframe.columns[n+3]])))\n",
    "        else:\n",
    "            sns.histplot(dataframe, x=dataframe.columns[n+3], hue=dataframe.columns[0], ax=ax)\n",
    "    peaks = []\n",
    "    maxs = []\n",
    "    for res in responses:\n",
    "        peak = detect_peaks(res)\n",
    "        peaks.extend(peak['peaks'])\n",
    "        maxs.extend(peak['max'])\n",
    "    sns.histplot(peaks, ax=axs[-1], color='tab:pink', label=(\"peaks\"), kde = True)\n",
    "    sns.scatterplot(y=[axs[-1].get_ylim()[1]//4]*len(maxs), x=maxs, ax=axs[-1], s=100, color='tab:brown', label=\"maxs\")\n",
    "    axs[-1].set_xlabel('stim_process_position')\n",
    "    axs[-1].xaxis.set_major_formatter(PercentFormatter())\n",
    "    \n",
    "    plt.savefig(os.path.join(PATH_RESULT, suptitle.get_text()))\n",
    "#     fig = plt.figure().suptitle(f'Pairplot for S{i}')\n",
    "#     sns.pairplot(dataframe, hue=dataframe.columns[0])\n",
    "    del X, y, dataframe\n",
    "    \n",
    "    #individual fvs save\n",
    "    fv = db.get_fv(source = SOURCE, channels = CHANNELS, subjects = SUBJECTS, \n",
    "                   sessions = SESSIONS, labels = LABELS\n",
    "                  )\n",
    "    lab = db.get_onehot(subjects = SUBJECTS, \n",
    "                   sessions = SESSIONS, labels = LABELS\n",
    "                       )\n",
    "    meta = db.get_metadata()\n",
    "    \n",
    "    global_users[f'S{i}'] = {\n",
    "        'X': os.path.join(PATH_FVS, f'X_S{i}.npy'),\n",
    "        'y': os.path.join(PATH_FVS, f'y_S{i}.npy'),\n",
    "        'meta': os.path.join(PATH_FVS, f'meta_S{i}.txt'),\n",
    "    }\n",
    "    np.save(global_users[f'S{i}']['X'], fv)\n",
    "    np.save(global_users[f'S{i}']['y'], lab)\n",
    "    with open(global_users[f'S{i}']['meta'], 'w') as f:\n",
    "        f.write(str(meta))\n",
    "    \n",
    "    del fv, lab, meta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54eacae",
   "metadata": {},
   "source": [
    "## Global Analysis\n",
    "Analysis carried out user by user. While we analyze each one, we also generate the necessary files for the global analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484337a1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame(columns=[\"user\", \"stim_number\", \"stim_moment\", \"max_peak_bin\", \"max_peak_energy\", \"max_peak_channel\", \"max_peak_freq\"])\n",
    "for s in global_users:\n",
    "    X, y = np.load(global_users[s]['X']), np.load(global_users[s]['y'])\n",
    "    dataframe, responses = pairplot_df(X, y, s, dataframe)\n",
    "    #fig = plt.figure(figsize=(15,5)).suptitle(f'Prevalent channel for {s}')\n",
    "    #sns.lineplot(responses)\n",
    "\n",
    "dataframe.pop('max_peak_bin') #for display this should not be necessary having channel and frequency\n",
    "fig, axs = plt.subplots(1, len(dataframe.columns)-2)\n",
    "fig.set_figheight(5)\n",
    "fig.set_figwidth(30)\n",
    "suptitle = fig.suptitle(f'Histograms for global')\n",
    "for n, ax in enumerate(axs[:-1]):\n",
    "    if dataframe.columns[n+3] != 'max_peak_energy':\n",
    "        sns.histplot(dataframe, x=dataframe.columns[n+3], hue=dataframe.columns[0], ax=ax, binwidth = 0.5)\n",
    "    else:\n",
    "        sns.histplot(dataframe, x=dataframe.columns[n+3], hue=dataframe.columns[0], ax=ax)\n",
    "peaks = []\n",
    "maxs = []\n",
    "for res in responses:\n",
    "    peak = detect_peaks(res)\n",
    "    peaks.extend(peak['peaks'])\n",
    "    maxs.extend(peak['max'])\n",
    "sns.histplot(peaks, ax=axs[-1], color='tab:blue', label=\"peaks\", kde = True)\n",
    "sns.scatterplot(y=[axs[-1].get_ylim()[1]//4]*len(maxs), x=maxs, ax=axs[-1], s=100, color='tab:orange', label=\"maxs\")\n",
    "axs[-1].set_xlabel('peaks_stim_position')\n",
    "axs[-1].xaxis.set_major_formatter(PercentFormatter())\n",
    "\n",
    "plt.savefig(os.path.join(PATH_RESULT, suptitle.get_text()))\n",
    "#fig = plt.figure().suptitle(f'Pairplot for global')\n",
    "#sns.pairplot(dataframe, hue=dataframe.columns[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
